# CoreML ì¸ì½”ë” ìµœì í™” Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** large-v3-turbo ëª¨ë¸ + CoreML ì¸ì½”ë”ë¡œ SimulWhisper ìµœì í™”

**Architecture:** whisper.cppë¡œ CoreML ëª¨ë¸ ìƒì„± â†’ Neural Engine ê°€ì† â†’ ì‹¤ì‹œê°„ ì „ì‚¬

**Tech Stack:** whisper.cpp, CoreML, large-v3-turbo, Apple Neural Engine

---

# Part 1: ì‚¬ì „ ì§€ì‹ ìŠµë“ (êµ¬í˜„ ì „ í•„ìˆ˜)

## í•™ìŠµ ëª©í‘œ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì•„ë˜ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆì–´ì•¼ êµ¬í˜„ì„ ê²€ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ“š ê°œë… ì´í•´ í™•ì¸

#### Q1. Whisper ì•„í‚¤í…ì²˜
```
ì§ˆë¬¸: Whisperì˜ ë‘ ê°€ì§€ ì£¼ìš” ì»´í¬ë„ŒíŠ¸ëŠ”?
ì •ë‹µ: ì¸ì½”ë”(Encoder)ì™€ ë””ì½”ë”(Decoder)

ì§ˆë¬¸: ì–´ëŠ ë¶€ë¶„ì´ ë” ë¬´ê±°ìš´ê°€?
ì •ë‹µ: ì¸ì½”ë” (ì˜¤ë””ì˜¤ â†’ ë²¡í„° ë³€í™˜, ëŒ€ë¶€ë¶„ì˜ ì—°ì‚°)

ì§ˆë¬¸: turbo ëª¨ë¸ì´ ë¹ ë¥¸ ì´ìœ ëŠ”?
ì •ë‹µ: ë””ì½”ë” ë ˆì´ì–´ë¥¼ 32ê°œ â†’ 4ê°œë¡œ ì¤„ì„ (distillation)
```

#### Q2. í•˜ë“œì›¨ì–´ ê°€ì†
```
ì§ˆë¬¸: Apple Siliconì˜ Neural Engineì´ë€?
ì •ë‹µ: í–‰ë ¬ ì—°ì‚° ì „ìš© í•˜ë“œì›¨ì–´ (AI ê°€ì†ê¸°)

ì§ˆë¬¸: CoreMLì˜ ì—­í• ì€?
ì •ë‹µ: Neural Engineì—ì„œ ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ ë³€í™˜/ìµœì í™”

ì§ˆë¬¸: MLX vs CoreML ì°¨ì´ëŠ”?
ì •ë‹µ: MLX = CPU/GPU ì‚¬ìš©, CoreML = Neural Engine ì‚¬ìš© (ë” ë¹ ë¦„)
```

#### Q3. íŒŒì¼ í˜•ì‹
```
ì§ˆë¬¸: .mlpackage íŒŒì¼ì´ë€?
ì •ë‹µ: CoreML ëª¨ë¸ íŒ¨í‚¤ì§€ (Neural Engineìš©ìœ¼ë¡œ ë³€í™˜ëœ ëª¨ë¸)

ì§ˆë¬¸: .mlmodelcë€?
ì •ë‹µ: ì»´íŒŒì¼ëœ CoreML ëª¨ë¸ (ì²« ì‹¤í–‰ ì‹œ ìë™ ìƒì„±)

ì§ˆë¬¸: ggml- ì ‘ë‘ì‚¬ íŒŒì¼ë“¤ì´ë€?
ì •ë‹µ: whisper.cppì˜ ì–‘ìí™”ëœ ëª¨ë¸ í˜•ì‹
```

#### Q4. ê²½ë¡œì™€ íƒì§€
```
ì§ˆë¬¸: SimulWhisperê°€ CoreML ëª¨ë¸ì„ ì°¾ëŠ” ê²½ë¡œëŠ”?
ì •ë‹µ:
  - backend/models/
  - backend/simul_whisper/models/
  - backend/simul_whisper/whisper.cpp/models/

ì§ˆë¬¸: CoreML ëª¨ë¸ íŒŒì¼ëª… íŒ¨í„´ì€?
ì •ë‹µ: coreml-encoder-{ëª¨ë¸ëª…}.mlpackage
```

---

## ğŸ§ª ì‹¤ìŠµ ê²€ì¦ ì§ˆë¬¸ (êµ¬í˜„ ì¤‘ ì‚¬ìš©)

### Task 1 ê²€ì¦: whisper.cpp í´ë¡ 
```bash
# ë‹¹ì‹ ì´ í™•ì¸í•  ëª…ë ¹ì–´:
ls backend/simul_whisper/whisper.cpp/models/generate-coreml-model.sh

# ì˜ˆìƒ ê²°ê³¼: íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨
# ì‹¤íŒ¨ ì‹œ: í´ë¡ ì´ ì œëŒ€ë¡œ ì•ˆ ëœ ê²ƒ
```

**ê²€ì¦ ì§ˆë¬¸:**
- [ ] `whisper.cpp/models/` í´ë” ì•ˆì— `generate-coreml-model.sh`ê°€ ìˆëŠ”ê°€?
- [ ] `whisper.cpp/README.md`ê°€ ì¡´ì¬í•˜ëŠ”ê°€?

---

### Task 2 ê²€ì¦: ì˜ì¡´ì„±
```bash
# ë‹¹ì‹ ì´ í™•ì¸í•  ëª…ë ¹ì–´:
python3 -c "import coremltools; import ane_transformers; import whisper; print('OK')"

# ì˜ˆìƒ ê²°ê³¼: OK
# ì‹¤íŒ¨ ì‹œ: í•´ë‹¹ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í•„ìš”
```

**ê²€ì¦ ì§ˆë¬¸:**
- [ ] `coremltools` import ì„±ê³µ?
- [ ] `ane_transformers` import ì„±ê³µ?
- [ ] `whisper` (openai-whisper) import ì„±ê³µ?

---

### Task 3 ê²€ì¦: CoreML ëª¨ë¸ ìƒì„±
```bash
# ë‹¹ì‹ ì´ í™•ì¸í•  ëª…ë ¹ì–´:
ls -la backend/simul_whisper/whisper.cpp/models/ | grep -E "coreml|mlpackage"

# ì˜ˆìƒ ê²°ê³¼: coreml-encoder-large-v3-turbo.mlpackage í´ë” ì¡´ì¬
# ì‹¤íŒ¨ ì‹œ: ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‹¤íŒ¨ ë˜ëŠ” ëª¨ë¸ëª… ì˜¤ë¥˜
```

**ê²€ì¦ ì§ˆë¬¸:**
- [ ] `coreml-encoder-large-v3-turbo.mlpackage/` ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ê°€?
- [ ] í•´ë‹¹ í´ë” í¬ê¸°ê°€ 0ì´ ì•„ë‹Œê°€? (ìµœì†Œ ìˆ˜ë°± MB)
- [ ] í´ë” ì•ˆì— `Manifest.json`ì´ ìˆëŠ”ê°€?

**ì˜ˆìƒ í´ë” êµ¬ì¡°:**
```
coreml-encoder-large-v3-turbo.mlpackage/
â”œâ”€â”€ Manifest.json
â”œâ”€â”€ Data/
â”‚   â””â”€â”€ com.apple.CoreML/
â”‚       â””â”€â”€ model.mlmodel
â””â”€â”€ ...
```

---

### Task 4 ê²€ì¦: ê²½ë¡œ ì„¤ì •
```bash
# ë‹¹ì‹ ì´ í™•ì¸í•  ëª…ë ¹ì–´:
ls -la backend/simul_whisper/models/

# ì˜ˆìƒ ê²°ê³¼: coreml-encoder-large-v3-turbo.mlpackage ì‹¬ë³¼ë¦­ ë§í¬
```

**ê²€ì¦ ì§ˆë¬¸:**
- [ ] ì‹¬ë³¼ë¦­ ë§í¬ê°€ ì˜¬ë°”ë¥¸ ê²½ë¡œë¥¼ ê°€ë¦¬í‚¤ëŠ”ê°€?
- [ ] `ls -la`ì—ì„œ `->` í‘œì‹œê°€ ë³´ì´ëŠ”ê°€?

---

### Task 5 ê²€ì¦: ì„œë²„ ì‹œì‘
```bash
# ë‹¹ì‹ ì´ í™•ì¸í•  ë¡œê·¸:
uvicorn main:app --port 8000

# ì„±ê³µ ë¡œê·¸ (ì´ê²ƒì´ ë³´ì—¬ì•¼ í•¨):
"Loading CoreML encoder from ..."
"INFO: Application startup complete"

# ì‹¤íŒ¨ ë¡œê·¸ (ì´ê²ƒì´ ë³´ì´ë©´ ì•ˆ ë¨):
"Failed to initialize CoreML encoder"
"Falling back to MLX encoder"
```

**ê²€ì¦ ì§ˆë¬¸:**
- [ ] "Loading CoreML encoder" ë©”ì‹œì§€ê°€ ë³´ì´ëŠ”ê°€?
- [ ] "Falling back" ë©”ì‹œì§€ê°€ ì—†ëŠ”ê°€?
- [ ] Health ì²´í¬ ê²°ê³¼ê°€ `SimulWhisperService`ì¸ê°€?

```bash
curl http://localhost:8000/health
# ì˜ˆìƒ: {"status":"ok","whisper_service":"SimulWhisperService"}
```

---

### Task 6 ê²€ì¦: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
```
# ì²´ê° í…ŒìŠ¤íŠ¸:
1. í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë…¹ìŒ ì‹œì‘
2. ë§í•˜ê¸° ì‹œì‘
3. í…ìŠ¤íŠ¸ê°€ ë‚˜íƒ€ë‚˜ëŠ” ì‹œê°„ ì¸¡ì •

# ê¸°ëŒ€ê°’:
- CoreML ì´ì „: ë§í•˜ê³  ~1ì´ˆ í›„ í…ìŠ¤íŠ¸ í‘œì‹œ
- CoreML ì´í›„: ë§í•˜ê³  ~0.2ì´ˆ í›„ í…ìŠ¤íŠ¸ í‘œì‹œ
```

**ê²€ì¦ ì§ˆë¬¸:**
- [ ] ì²´ê° ì§€ì—°ì´ í™•ì‹¤íˆ ì¤„ì—ˆëŠ”ê°€?
- [ ] í•œêµ­ì–´ ì¸ì‹ í’ˆì§ˆì´ ìœ ì§€ë˜ëŠ”ê°€?

---

# Part 2: êµ¬í˜„ ë‹¨ê³„

## Task 1: whisper.cpp í´ë¡ 

**Files:**
- Create: `backend/simul_whisper/whisper.cpp/`

**Step 1:**
```bash
rm -rf /Users/song-giung/code/side-project/live-point/backend/simul_whisper/whisper.cpp
```

**Step 2:**
```bash
cd /Users/song-giung/code/side-project/live-point/backend/simul_whisper
git clone https://github.com/ggml-org/whisper.cpp.git
```

**Step 3: ê²€ì¦**
```bash
ls backend/simul_whisper/whisper.cpp/models/generate-coreml-model.sh
# íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨
```

---

## Task 2: ì˜ì¡´ì„± í™•ì¸

**Step 1:**
```bash
python3 -c "import coremltools; import ane_transformers; import whisper; print('All dependencies OK')"
```

ëˆ„ë½ëœ íŒ¨í‚¤ì§€ê°€ ìˆìœ¼ë©´:
```bash
pip install coremltools ane_transformers openai-whisper
```

---

## Task 3: CoreML ëª¨ë¸ ìƒì„± (large-v3-turbo)

**Files:**
- Create: `backend/simul_whisper/whisper.cpp/models/coreml-encoder-large-v3-turbo.mlpackage/`

**Step 1:**
```bash
cd /Users/song-giung/code/side-project/live-point/backend/simul_whisper/whisper.cpp/models
chmod +x generate-coreml-model.sh
./generate-coreml-model.sh large-v3-turbo
```

âš ï¸ **ì¤‘ìš”**: 30ë¶„-1ì‹œê°„ ì†Œìš” ê°€ëŠ¥. ë©”ëª¨ë¦¬ 8GB+ í•„ìš”.

**Step 2: ê²€ì¦**
```bash
ls -la backend/simul_whisper/whisper.cpp/models/ | grep coreml
# coreml-encoder-large-v3-turbo.mlpackage í´ë”ê°€ ë³´ì—¬ì•¼ í•¨
```

---

## Task 4: simul_whisper_service.py ìˆ˜ì •

**Files:**
- Modify: `backend/simul_whisper_service.py`

**ë³€ê²½ ë‚´ìš©:**
```python
# ê¸°ì¡´ (line 51):
model_path = f"mlx-community/whisper-{self.model_name}-mlx"

# ë³€ê²½:
model_path = "mlx-community/whisper-large-v3-turbo-mlx"
```

**ê·¸ë¦¬ê³  .env íŒŒì¼:**
```env
WHISPER_MODEL=large-v3-turbo
```

---

## Task 5: ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„±

```bash
mkdir -p /Users/song-giung/code/side-project/live-point/backend/simul_whisper/models

ln -s ../whisper.cpp/models/coreml-encoder-large-v3-turbo.mlpackage \
      /Users/song-giung/code/side-project/live-point/backend/simul_whisper/models/coreml-encoder-large-v3-turbo.mlpackage
```

---

## Task 6: ì„œë²„ ì‹œì‘ ë° ê²€ì¦

```bash
cd /Users/song-giung/code/side-project/live-point/backend
uvicorn main:app --port 8000
```

**í™•ì¸ì‚¬í•­:**
1. ë¡œê·¸ì— "Loading CoreML encoder" ì¶œë ¥
2. `curl localhost:8000/health` â†’ SimulWhisperService
3. í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ì‚¬ í…ŒìŠ¤íŠ¸

---

# Part 3: ë¬¸ì œ ë°œìƒ ì‹œ ë””ë²„ê¹… ê°€ì´ë“œ

## ë¬¸ì œ: "Falling back to MLX encoder" ì¶œë ¥

**ì›ì¸ 1: CoreML ëª¨ë¸ì„ ëª» ì°¾ìŒ**
```bash
# ê²€ìƒ‰ ê²½ë¡œ í™•ì¸
python3 -c "
from simul_whisper.simul_whisper.coreml_encoder import CoreMLWhisperEncoder
paths = CoreMLWhisperEncoder.find_model_path('large-v3-turbo')
print(paths)
"
```

**ì›ì¸ 2: ëª¨ë¸ëª… ë¶ˆì¼ì¹˜**
```bash
# ì‹¤ì œ ìƒì„±ëœ íŒŒì¼ëª… í™•ì¸
ls backend/simul_whisper/whisper.cpp/models/ | grep coreml
# íŒŒì¼ëª…ì´ ë‹¤ë¥´ë©´ ì‹¬ë³¼ë¦­ ë§í¬ ë‹¤ì‹œ ìƒì„±
```

## ë¬¸ì œ: ëª¨ë¸ ìƒì„± ì‹¤íŒ¨

**ì›ì¸ 1: ë©”ëª¨ë¦¬ ë¶€ì¡±**
```bash
# ë” ì‘ì€ ëª¨ë¸ë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸
./generate-coreml-model.sh base
```

**ì›ì¸ 2: Xcode ë¯¸ì„¤ì¹˜**
```bash
xcode-select --install
```

---

# Part 4: ìµœì¢… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

êµ¬í˜„ ì™„ë£Œ í›„ ëª¨ë“  í•­ëª© ì²´í¬:

- [ ] `whisper.cpp` í´ë”ì— ì†ŒìŠ¤ì½”ë“œ ìˆìŒ
- [ ] `coreml-encoder-large-v3-turbo.mlpackage` ì¡´ì¬ (ìˆ˜ë°± MB)
- [ ] ì‹¬ë³¼ë¦­ ë§í¬ ì •ìƒ ì‘ë™
- [ ] ì„œë²„ ë¡œê·¸ì— "CoreML encoder" ë¡œë”© ë©”ì‹œì§€
- [ ] "Falling back" ë©”ì‹œì§€ ì—†ìŒ
- [ ] Health ì²´í¬ ì •ìƒ
- [ ] í”„ë¡ íŠ¸ì—”ë“œ ì „ì‚¬ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ì§€ì—° ì‹œê°„ ì²´ê° ê°œì„ 
