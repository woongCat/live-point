# live-point Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** ì‹¤ì‹œê°„ ìŒì„± ì „ì‚¬ + ìš”ì§€ ì¶”ì¶œ ì›¹ì•± êµ¬í˜„

**Architecture:** FastAPI ë°±ì—”ë“œê°€ WebSocketìœ¼ë¡œ ì˜¤ë””ì˜¤ë¥¼ ë°›ì•„ faster-whisperë¡œ ì „ì‚¬í•˜ê³ , pause ê°ì§€ ì‹œ OpenAI APIë¡œ ìš”ì§€ ì¶”ì¶œ. React í”„ë¡ íŠ¸ì—”ë“œëŠ” 3ë‹¨ ë ˆì´ì•„ì›ƒ (íˆìŠ¤í† ë¦¬ | ì „ì‚¬ | ìš”ì§€).

**Tech Stack:** Python 3.11+, FastAPI, faster-whisper, OpenAI API, React, TypeScript, Vite, Tailwind, Zustand, Dexie.js

---

## Task 1: Backend í”„ë¡œì íŠ¸ ì´ˆê¸°í™”

**Files:**
- Create: `backend/requirements.txt`
- Create: `backend/main.py`
- Create: `backend/.env.example`

**Step 1: requirements.txt ìƒì„±**

```txt
fastapi==0.109.0
uvicorn[standard]==0.27.0
python-dotenv==1.0.0
websockets==12.0
faster-whisper==1.0.1
openai==1.12.0
numpy==1.26.3
```

**Step 2: .env.example ìƒì„±**

```
OPENAI_API_KEY=sk-your-key-here
WHISPER_MODEL=base
```

**Step 3: main.py ê¸°ë³¸ êµ¬ì¡° ìƒì„±**

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="live-point")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/health")
async def health():
    return {"status": "ok"}
```

**Step 4: ì„œë²„ ì‹¤í–‰ í…ŒìŠ¤íŠ¸**

```bash
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --reload --port 8000
# ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8000/health í™•ì¸
```

**Step 5: Commit**

```bash
git init
git add backend/
git commit -m "feat: backend í”„ë¡œì íŠ¸ ì´ˆê¸°í™”"
```

---

## Task 2: Whisper ì„œë¹„ìŠ¤ êµ¬í˜„

**Files:**
- Create: `backend/whisper_service.py`
- Modify: `backend/main.py`

**Step 1: whisper_service.py ìƒì„±**

```python
import os
import numpy as np
from faster_whisper import WhisperModel

class WhisperService:
    def __init__(self):
        model_size = os.getenv("WHISPER_MODEL", "base")
        self.model = WhisperModel(
            model_size,
            device="cpu",
            compute_type="int8"
        )

    def transcribe(self, audio_data: bytes) -> str:
        """16kHz mono PCM ë°”ì´íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0

        segments, _ = self.model.transcribe(
            audio_np,
            language="ko",
            vad_filter=True,
            vad_parameters=dict(min_silence_duration_ms=500)
        )

        text = " ".join([seg.text for seg in segments])
        return text.strip()

whisper_service = WhisperService()
```

**Step 2: main.pyì— import ì¶”ê°€**

```python
from dotenv import load_dotenv
load_dotenv()

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from whisper_service import whisper_service

app = FastAPI(title="live-point")

# ... ê¸°ì¡´ CORS ì„¤ì • ...

@app.get("/health")
async def health():
    return {"status": "ok", "whisper": "loaded"}
```

**Step 3: ì„œë²„ ì¬ì‹œì‘ ë° health í™•ì¸**

```bash
uvicorn main:app --reload --port 8000
# http://localhost:8000/health â†’ {"status": "ok", "whisper": "loaded"}
```

**Step 4: Commit**

```bash
git add backend/whisper_service.py backend/main.py
git commit -m "feat: faster-whisper ì„œë¹„ìŠ¤ êµ¬í˜„"
```

---

## Task 3: LLM ì„œë¹„ìŠ¤ (ìš”ì§€ ì¶”ì¶œ) êµ¬í˜„

**Files:**
- Create: `backend/llm_service.py`

**Step 1: llm_service.py ìƒì„±**

```python
import os
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

SYSTEM_PROMPT = """ë„ˆëŠ” ìš”ì§€ ì¶”ì¶œê¸°ì•¼. ì‚¬ìš©ìê°€ ë§í•œ ë‚´ìš©ì—ì„œ í•µì‹¬ ì˜ë„ë§Œ ì¶”ì¶œí•´.
- í•„ëŸ¬(ìŒ, ê·¸ëŸ¬ë‹ˆê¹Œ, ë­ë„ê¹Œ, ì–´)ì™€ ë°˜ë³µ ì œê±°
- ì§„ì§œ í•˜ê³  ì‹¶ì€ ë§ì„ 1-2ë¬¸ì¥ìœ¼ë¡œ
- í•œêµ­ì–´ë¡œ ì‘ë‹µ
- ìš”ì§€ë§Œ ì¶œë ¥, ë‹¤ë¥¸ ì„¤ëª… ì—†ì´"""

async def extract_point(transcript: str) -> str:
    """ì „ì‚¬ í…ìŠ¤íŠ¸ì—ì„œ ìš”ì§€ ì¶”ì¶œ (ìŠ¤íŠ¸ë¦¬ë°)"""
    if not transcript.strip():
        return ""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": transcript}
        ],
        max_tokens=150,
        temperature=0.3,
    )

    return response.choices[0].message.content.strip()

async def extract_point_stream(transcript: str):
    """ì „ì‚¬ í…ìŠ¤íŠ¸ì—ì„œ ìš”ì§€ ì¶”ì¶œ (ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„°)"""
    if not transcript.strip():
        return

    stream = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": transcript}
        ],
        max_tokens=150,
        temperature=0.3,
        stream=True,
    )

    for chunk in stream:
        if chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content
```

**Step 2: Commit**

```bash
git add backend/llm_service.py
git commit -m "feat: OpenAI ìš”ì§€ ì¶”ì¶œ ì„œë¹„ìŠ¤ êµ¬í˜„"
```

---

## Task 4: WebSocket í•¸ë“¤ëŸ¬ êµ¬í˜„

**Files:**
- Create: `backend/websocket_handler.py`
- Modify: `backend/main.py`

**Step 1: websocket_handler.py ìƒì„±**

```python
import json
import asyncio
from fastapi import WebSocket, WebSocketDisconnect
from whisper_service import whisper_service
from llm_service import extract_point_stream

class AudioBuffer:
    def __init__(self, threshold_seconds: float = 2.5, sample_rate: int = 16000):
        self.buffer = bytearray()
        self.threshold_bytes = int(threshold_seconds * sample_rate * 2)  # 16-bit = 2 bytes
        self.silence_threshold = 1.5  # seconds
        self.last_voice_time = 0

    def add(self, chunk: bytes) -> bytes | None:
        self.buffer.extend(chunk)
        if len(self.buffer) >= self.threshold_bytes:
            data = bytes(self.buffer)
            self.buffer.clear()
            return data
        return None

class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

manager = ConnectionManager()

async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    audio_buffer = AudioBuffer()
    transcript_buffer = ""

    try:
        while True:
            data = await websocket.receive()

            if "bytes" in data:
                # ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ 
                audio_chunk = data["bytes"]
                buffered = audio_buffer.add(audio_chunk)

                if buffered:
                    # Whisper ì „ì‚¬
                    text = whisper_service.transcribe(buffered)
                    if text:
                        transcript_buffer += " " + text
                        await websocket.send_json({
                            "type": "transcript",
                            "text": text
                        })

            elif "text" in data:
                msg = json.loads(data["text"])

                if msg.get("type") == "pause":
                    # ì¹¨ë¬µ ê°ì§€ â†’ ìš”ì§€ ì¶”ì¶œ
                    if transcript_buffer.strip():
                        point_text = ""
                        async for chunk in extract_point_stream(transcript_buffer):
                            point_text += chunk
                            await websocket.send_json({
                                "type": "point_chunk",
                                "text": chunk
                            })

                        await websocket.send_json({
                            "type": "point_complete",
                            "source": transcript_buffer.strip(),
                            "point": point_text
                        })
                        transcript_buffer = ""

                elif msg.get("type") == "reset":
                    transcript_buffer = ""
                    audio_buffer.buffer.clear()

    except WebSocketDisconnect:
        manager.disconnect(websocket)
```

**Step 2: main.pyì— WebSocket ë¼ìš°íŠ¸ ì¶”ê°€**

```python
from dotenv import load_dotenv
load_dotenv()

from fastapi import FastAPI, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from whisper_service import whisper_service
from websocket_handler import websocket_endpoint

app = FastAPI(title="live-point")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/health")
async def health():
    return {"status": "ok"}

@app.websocket("/ws")
async def ws(websocket: WebSocket):
    await websocket_endpoint(websocket)
```

**Step 3: Commit**

```bash
git add backend/websocket_handler.py backend/main.py
git commit -m "feat: WebSocket í•¸ë“¤ëŸ¬ êµ¬í˜„ (ì „ì‚¬ + ìš”ì§€ ì¶”ì¶œ)"
```

---

## Task 5: Frontend í”„ë¡œì íŠ¸ ì´ˆê¸°í™”

**Files:**
- Create: `frontend/` (Vite + React + TypeScript)

**Step 1: Vite í”„ë¡œì íŠ¸ ìƒì„±**

```bash
cd /Users/kiwi/Code/side-project/live-point
npm create vite@latest frontend -- --template react-ts
cd frontend
npm install
```

**Step 2: Tailwind CSS ì„¤ì¹˜**

```bash
npm install -D tailwindcss postcss autoprefixer
npx tailwindcss init -p
```

**Step 3: tailwind.config.js ìˆ˜ì •**

```javascript
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {},
  },
  plugins: [],
}
```

**Step 4: src/index.css ìˆ˜ì •**

```css
@tailwind base;
@tailwind components;
@tailwind utilities;
```

**Step 5: ì¶”ê°€ ì˜ì¡´ì„± ì„¤ì¹˜**

```bash
npm install zustand dexie uuid
npm install -D @types/uuid
```

**Step 6: ê°œë°œ ì„œë²„ í…ŒìŠ¤íŠ¸**

```bash
npm run dev
# http://localhost:5173 í™•ì¸
```

**Step 7: Commit**

```bash
cd ..
git add frontend/
git commit -m "feat: frontend í”„ë¡œì íŠ¸ ì´ˆê¸°í™” (Vite + React + Tailwind)"
```

---

## Task 6: íƒ€ì… ì •ì˜ ë° Zustand ìŠ¤í† ì–´

**Files:**
- Create: `frontend/src/types.ts`
- Create: `frontend/src/stores/sessionStore.ts`

**Step 1: types.ts ìƒì„±**

```typescript
export interface Point {
  id: string;
  timestamp: Date;
  sourceText: string;
  point: string;
}

export interface Session {
  id: string;
  createdAt: Date;
  title: string;
  transcript: string;
  points: Point[];
}

export interface WebSocketMessage {
  type: 'transcript' | 'point_chunk' | 'point_complete' | 'pause' | 'reset';
  text?: string;
  source?: string;
  point?: string;
}
```

**Step 2: sessionStore.ts ìƒì„±**

```typescript
import { create } from 'zustand';
import { v4 as uuid } from 'uuid';
import type { Session, Point } from '../types';

interface SessionState {
  sessions: Session[];
  currentSession: Session | null;
  currentTranscript: string;
  currentPointText: string;
  isRecording: boolean;

  // Actions
  startNewSession: () => void;
  loadSession: (id: string) => void;
  appendTranscript: (text: string) => void;
  setPointText: (text: string) => void;
  appendPointText: (chunk: string) => void;
  addPoint: (sourceText: string, point: string) => void;
  setRecording: (recording: boolean) => void;
  setSessions: (sessions: Session[]) => void;
}

export const useSessionStore = create<SessionState>((set, get) => ({
  sessions: [],
  currentSession: null,
  currentTranscript: '',
  currentPointText: '',
  isRecording: false,

  startNewSession: () => {
    const newSession: Session = {
      id: uuid(),
      createdAt: new Date(),
      title: `ì„¸ì…˜ ${new Date().toLocaleString('ko-KR')}`,
      transcript: '',
      points: [],
    };
    set({
      currentSession: newSession,
      currentTranscript: '',
      currentPointText: '',
    });
  },

  loadSession: (id: string) => {
    const session = get().sessions.find(s => s.id === id);
    if (session) {
      set({
        currentSession: session,
        currentTranscript: session.transcript,
        currentPointText: '',
      });
    }
  },

  appendTranscript: (text: string) => {
    set(state => ({
      currentTranscript: state.currentTranscript + ' ' + text,
      currentSession: state.currentSession ? {
        ...state.currentSession,
        transcript: state.currentSession.transcript + ' ' + text,
      } : null,
    }));
  },

  setPointText: (text: string) => {
    set({ currentPointText: text });
  },

  appendPointText: (chunk: string) => {
    set(state => ({
      currentPointText: state.currentPointText + chunk,
    }));
  },

  addPoint: (sourceText: string, point: string) => {
    const newPoint: Point = {
      id: uuid(),
      timestamp: new Date(),
      sourceText,
      point,
    };
    set(state => ({
      currentPointText: '',
      currentSession: state.currentSession ? {
        ...state.currentSession,
        points: [...state.currentSession.points, newPoint],
      } : null,
    }));
  },

  setRecording: (recording: boolean) => {
    set({ isRecording: recording });
  },

  setSessions: (sessions: Session[]) => {
    set({ sessions });
  },
}));
```

**Step 3: Commit**

```bash
git add frontend/src/types.ts frontend/src/stores/
git commit -m "feat: íƒ€ì… ì •ì˜ ë° Zustand ìŠ¤í† ì–´ êµ¬í˜„"
```

---

## Task 7: IndexedDB ì €ì¥ (Dexie)

**Files:**
- Create: `frontend/src/db.ts`
- Modify: `frontend/src/stores/sessionStore.ts`

**Step 1: db.ts ìƒì„±**

```typescript
import Dexie, { type Table } from 'dexie';
import type { Session } from './types';

class LivePointDB extends Dexie {
  sessions!: Table<Session>;

  constructor() {
    super('livepoint');
    this.version(1).stores({
      sessions: 'id, createdAt',
    });
  }
}

export const db = new LivePointDB();

export async function saveSession(session: Session): Promise<void> {
  await db.sessions.put(session);
}

export async function loadAllSessions(): Promise<Session[]> {
  return await db.sessions.orderBy('createdAt').reverse().toArray();
}

export async function deleteSession(id: string): Promise<void> {
  await db.sessions.delete(id);
}
```

**Step 2: Commit**

```bash
git add frontend/src/db.ts
git commit -m "feat: IndexedDB ì €ì¥ì†Œ (Dexie) êµ¬í˜„"
```

---

## Task 8: ì˜¤ë””ì˜¤ ìº¡ì²˜ í›…

**Files:**
- Create: `frontend/src/hooks/useAudioCapture.ts`

**Step 1: useAudioCapture.ts ìƒì„±**

```typescript
import { useRef, useCallback } from 'react';

interface UseAudioCaptureOptions {
  onAudioData: (data: ArrayBuffer) => void;
  sampleRate?: number;
}

export function useAudioCapture({ onAudioData, sampleRate = 16000 }: UseAudioCaptureOptions) {
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);

  const start = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
        },
      });

      mediaStreamRef.current = stream;
      audioContextRef.current = new AudioContext({ sampleRate });

      const source = audioContextRef.current.createMediaStreamSource(stream);
      const processor = audioContextRef.current.createScriptProcessor(4096, 1, 1);

      processor.onaudioprocess = (e) => {
        const inputData = e.inputBuffer.getChannelData(0);
        // Float32 â†’ Int16 ë³€í™˜
        const int16Data = new Int16Array(inputData.length);
        for (let i = 0; i < inputData.length; i++) {
          int16Data[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
        }
        onAudioData(int16Data.buffer);
      };

      source.connect(processor);
      processor.connect(audioContextRef.current.destination);
      processorRef.current = processor;

    } catch (error) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', error);
      throw error;
    }
  }, [onAudioData, sampleRate]);

  const stop = useCallback(() => {
    processorRef.current?.disconnect();
    audioContextRef.current?.close();
    mediaStreamRef.current?.getTracks().forEach(track => track.stop());

    processorRef.current = null;
    audioContextRef.current = null;
    mediaStreamRef.current = null;
  }, []);

  return { start, stop };
}
```

**Step 2: Commit**

```bash
git add frontend/src/hooks/useAudioCapture.ts
git commit -m "feat: ì˜¤ë””ì˜¤ ìº¡ì²˜ í›… êµ¬í˜„"
```

---

## Task 9: WebSocket í›…

**Files:**
- Create: `frontend/src/hooks/useWebSocket.ts`

**Step 1: useWebSocket.ts ìƒì„±**

```typescript
import { useRef, useCallback, useEffect } from 'react';
import type { WebSocketMessage } from '../types';

interface UseWebSocketOptions {
  url: string;
  onTranscript: (text: string) => void;
  onPointChunk: (chunk: string) => void;
  onPointComplete: (source: string, point: string) => void;
}

export function useWebSocket({ url, onTranscript, onPointChunk, onPointComplete }: UseWebSocketOptions) {
  const wsRef = useRef<WebSocket | null>(null);
  const reconnectTimeoutRef = useRef<number>();

  const connect = useCallback(() => {
    if (wsRef.current?.readyState === WebSocket.OPEN) return;

    const ws = new WebSocket(url);

    ws.onopen = () => {
      console.log('WebSocket ì—°ê²°ë¨');
    };

    ws.onmessage = (event) => {
      const msg: WebSocketMessage = JSON.parse(event.data);

      switch (msg.type) {
        case 'transcript':
          if (msg.text) onTranscript(msg.text);
          break;
        case 'point_chunk':
          if (msg.text) onPointChunk(msg.text);
          break;
        case 'point_complete':
          if (msg.source && msg.point) onPointComplete(msg.source, msg.point);
          break;
      }
    };

    ws.onclose = () => {
      console.log('WebSocket ì—°ê²° ì¢…ë£Œ');
      // 3ì´ˆ í›„ ì¬ì—°ê²° ì‹œë„
      reconnectTimeoutRef.current = window.setTimeout(connect, 3000);
    };

    ws.onerror = (error) => {
      console.error('WebSocket ì—ëŸ¬:', error);
    };

    wsRef.current = ws;
  }, [url, onTranscript, onPointChunk, onPointComplete]);

  const disconnect = useCallback(() => {
    clearTimeout(reconnectTimeoutRef.current);
    wsRef.current?.close();
    wsRef.current = null;
  }, []);

  const sendAudio = useCallback((data: ArrayBuffer) => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(data);
    }
  }, []);

  const sendPause = useCallback(() => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({ type: 'pause' }));
    }
  }, []);

  const sendReset = useCallback(() => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({ type: 'reset' }));
    }
  }, []);

  useEffect(() => {
    return () => {
      disconnect();
    };
  }, [disconnect]);

  return { connect, disconnect, sendAudio, sendPause, sendReset };
}
```

**Step 2: Commit**

```bash
git add frontend/src/hooks/useWebSocket.ts
git commit -m "feat: WebSocket í›… êµ¬í˜„"
```

---

## Task 10: UI ì»´í¬ë„ŒíŠ¸ - HistoryPanel

**Files:**
- Create: `frontend/src/components/HistoryPanel.tsx`

**Step 1: HistoryPanel.tsx ìƒì„±**

```typescript
import { useSessionStore } from '../stores/sessionStore';

export function HistoryPanel() {
  const { sessions, currentSession, loadSession, startNewSession } = useSessionStore();

  return (
    <div className="w-64 bg-gray-50 border-r border-gray-200 flex flex-col h-full">
      <div className="p-4 border-b border-gray-200">
        <button
          onClick={startNewSession}
          className="w-full py-2 px-4 bg-blue-500 text-white rounded-lg hover:bg-blue-600 transition-colors"
        >
          + ìƒˆ ì„¸ì…˜
        </button>
      </div>

      <div className="flex-1 overflow-y-auto">
        {sessions.map((session) => (
          <div
            key={session.id}
            onClick={() => loadSession(session.id)}
            className={`p-4 border-b border-gray-100 cursor-pointer hover:bg-gray-100 transition-colors ${
              currentSession?.id === session.id ? 'bg-blue-50' : ''
            }`}
          >
            <div className="text-sm font-medium text-gray-900 truncate">
              {session.title}
            </div>
            <div className="text-xs text-gray-500 mt-1">
              {new Date(session.createdAt).toLocaleDateString('ko-KR')}
            </div>
            <div className="text-xs text-gray-400 mt-1">
              â€¢ {session.points.length} points
            </div>
          </div>
        ))}

        {sessions.length === 0 && (
          <div className="p-4 text-sm text-gray-400 text-center">
            ì €ì¥ëœ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤
          </div>
        )}
      </div>
    </div>
  );
}
```

**Step 2: Commit**

```bash
git add frontend/src/components/HistoryPanel.tsx
git commit -m "feat: HistoryPanel ì»´í¬ë„ŒíŠ¸ êµ¬í˜„"
```

---

## Task 11: UI ì»´í¬ë„ŒíŠ¸ - TranscriptFlow

**Files:**
- Create: `frontend/src/components/TranscriptFlow.tsx`

**Step 1: TranscriptFlow.tsx ìƒì„±**

```typescript
import { useEffect, useRef } from 'react';
import { useSessionStore } from '../stores/sessionStore';

export function TranscriptFlow() {
  const { currentTranscript, isRecording } = useSessionStore();
  const containerRef = useRef<HTMLDivElement>(null);

  // ìë™ ìŠ¤í¬ë¡¤
  useEffect(() => {
    if (containerRef.current) {
      containerRef.current.scrollTop = containerRef.current.scrollHeight;
    }
  }, [currentTranscript]);

  return (
    <div className="flex-1 flex flex-col h-full bg-white">
      <div className="p-4 border-b border-gray-200 flex items-center gap-2">
        <h2 className="text-lg font-semibold text-gray-700">ì‹¤ì‹œê°„ ì „ì‚¬</h2>
        {isRecording && (
          <span className="flex items-center gap-1">
            <span className="w-2 h-2 bg-red-500 rounded-full animate-pulse" />
            <span className="text-sm text-red-500">ë…¹ìŒì¤‘</span>
          </span>
        )}
      </div>

      <div
        ref={containerRef}
        className="flex-1 p-4 overflow-y-auto"
      >
        {currentTranscript ? (
          <p className="text-gray-800 leading-relaxed whitespace-pre-wrap">
            {currentTranscript}
            {isRecording && <span className="animate-pulse">â–Œ</span>}
          </p>
        ) : (
          <p className="text-gray-400 text-center mt-8">
            ë…¹ìŒì„ ì‹œì‘í•˜ë©´ ì „ì‚¬ ë‚´ìš©ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤
          </p>
        )}
      </div>
    </div>
  );
}
```

**Step 2: Commit**

```bash
git add frontend/src/components/TranscriptFlow.tsx
git commit -m "feat: TranscriptFlow ì»´í¬ë„ŒíŠ¸ êµ¬í˜„"
```

---

## Task 12: UI ì»´í¬ë„ŒíŠ¸ - PointPanel

**Files:**
- Create: `frontend/src/components/PointPanel.tsx`

**Step 1: PointPanel.tsx ìƒì„±**

```typescript
import { useSessionStore } from '../stores/sessionStore';

export function PointPanel() {
  const { currentSession, currentPointText } = useSessionStore();

  const copyToClipboard = () => {
    if (!currentSession) return;
    const text = currentSession.points.map(p => `â€¢ ${p.point}`).join('\n');
    navigator.clipboard.writeText(text);
  };

  const exportMarkdown = () => {
    if (!currentSession) return;
    const md = `# ${currentSession.title}\n\n${currentSession.points
      .map(p => `- ${p.point}`)
      .join('\n')}`;

    const blob = new Blob([md], { type: 'text/markdown' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `${currentSession.title}.md`;
    a.click();
    URL.revokeObjectURL(url);
  };

  return (
    <div className="w-80 bg-gray-50 border-l border-gray-200 flex flex-col h-full">
      <div className="p-4 border-b border-gray-200">
        <h2 className="text-lg font-semibold text-gray-700">ìš”ì§€ (The Point)</h2>
      </div>

      <div className="flex-1 p-4 overflow-y-auto space-y-3">
        {currentSession?.points.map((point, index) => (
          <div
            key={point.id}
            className="p-3 bg-white rounded-lg shadow-sm border border-gray-100 animate-fade-in"
          >
            <p className="text-gray-800 text-sm">{point.point}</p>
            <p className="text-xs text-gray-400 mt-2 truncate">
              ì›ë¬¸: {point.sourceText.slice(0, 50)}...
            </p>
          </div>
        ))}

        {/* í˜„ì¬ ìƒì„± ì¤‘ì¸ ìš”ì§€ */}
        {currentPointText && (
          <div className="p-3 bg-blue-50 rounded-lg border border-blue-200 animate-pulse">
            <p className="text-blue-800 text-sm">{currentPointText}</p>
          </div>
        )}

        {!currentSession?.points.length && !currentPointText && (
          <p className="text-gray-400 text-center text-sm mt-8">
            ë§ì„ ë©ˆì¶”ë©´ ìš”ì§€ê°€ ì—¬ê¸°ì— ë‚˜íƒ€ë‚©ë‹ˆë‹¤
          </p>
        )}
      </div>

      <div className="p-4 border-t border-gray-200 flex gap-2">
        <button
          onClick={copyToClipboard}
          disabled={!currentSession?.points.length}
          className="flex-1 py-2 px-3 text-sm bg-gray-100 text-gray-700 rounded hover:bg-gray-200 disabled:opacity-50 disabled:cursor-not-allowed"
        >
          ë³µì‚¬
        </button>
        <button
          onClick={exportMarkdown}
          disabled={!currentSession?.points.length}
          className="flex-1 py-2 px-3 text-sm bg-gray-100 text-gray-700 rounded hover:bg-gray-200 disabled:opacity-50 disabled:cursor-not-allowed"
        >
          ë‚´ë³´ë‚´ê¸°
        </button>
      </div>
    </div>
  );
}
```

**Step 2: Commit**

```bash
git add frontend/src/components/PointPanel.tsx
git commit -m "feat: PointPanel ì»´í¬ë„ŒíŠ¸ êµ¬í˜„"
```

---

## Task 13: App ì»´í¬ë„ŒíŠ¸ í†µí•©

**Files:**
- Modify: `frontend/src/App.tsx`
- Create: `frontend/src/components/RecordButton.tsx`

**Step 1: RecordButton.tsx ìƒì„±**

```typescript
import { useSessionStore } from '../stores/sessionStore';

interface RecordButtonProps {
  onStart: () => void;
  onStop: () => void;
}

export function RecordButton({ onStart, onStop }: RecordButtonProps) {
  const { isRecording, setRecording, currentSession, startNewSession } = useSessionStore();

  const handleClick = () => {
    if (isRecording) {
      setRecording(false);
      onStop();
    } else {
      if (!currentSession) {
        startNewSession();
      }
      setRecording(true);
      onStart();
    }
  };

  return (
    <button
      onClick={handleClick}
      className={`px-4 py-2 rounded-lg font-medium transition-all ${
        isRecording
          ? 'bg-red-500 text-white hover:bg-red-600'
          : 'bg-blue-500 text-white hover:bg-blue-600'
      }`}
    >
      {isRecording ? 'â¹ ì¤‘ì§€' : 'ğŸ¤ ë…¹ìŒ'}
    </button>
  );
}
```

**Step 2: App.tsx ìˆ˜ì •**

```typescript
import { useEffect, useCallback, useRef } from 'react';
import { HistoryPanel } from './components/HistoryPanel';
import { TranscriptFlow } from './components/TranscriptFlow';
import { PointPanel } from './components/PointPanel';
import { RecordButton } from './components/RecordButton';
import { useSessionStore } from './stores/sessionStore';
import { useAudioCapture } from './hooks/useAudioCapture';
import { useWebSocket } from './hooks/useWebSocket';
import { loadAllSessions, saveSession } from './db';

const WS_URL = 'ws://localhost:8000/ws';
const PAUSE_THRESHOLD_MS = 1500;

function App() {
  const {
    currentSession,
    appendTranscript,
    appendPointText,
    addPoint,
    setSessions,
  } = useSessionStore();

  const lastAudioTimeRef = useRef<number>(Date.now());
  const pauseTimerRef = useRef<number>();

  const { connect, disconnect, sendAudio, sendPause } = useWebSocket({
    url: WS_URL,
    onTranscript: (text) => {
      appendTranscript(text);
      lastAudioTimeRef.current = Date.now();
    },
    onPointChunk: (chunk) => {
      appendPointText(chunk);
    },
    onPointComplete: (source, point) => {
      addPoint(source, point);
    },
  });

  const handleAudioData = useCallback((data: ArrayBuffer) => {
    sendAudio(data);
    lastAudioTimeRef.current = Date.now();

    // ì¹¨ë¬µ ê°ì§€ íƒ€ì´ë¨¸ ë¦¬ì…‹
    clearTimeout(pauseTimerRef.current);
    pauseTimerRef.current = window.setTimeout(() => {
      sendPause();
    }, PAUSE_THRESHOLD_MS);
  }, [sendAudio, sendPause]);

  const { start: startCapture, stop: stopCapture } = useAudioCapture({
    onAudioData: handleAudioData,
  });

  const handleStart = async () => {
    connect();
    await startCapture();
  };

  const handleStop = () => {
    clearTimeout(pauseTimerRef.current);
    stopCapture();
    sendPause(); // ë§ˆì§€ë§‰ ìš”ì§€ ì¶”ì¶œ
  };

  // ì„¸ì…˜ ë¡œë“œ
  useEffect(() => {
    loadAllSessions().then(setSessions);
  }, [setSessions]);

  // ì„¸ì…˜ ìë™ ì €ì¥
  useEffect(() => {
    if (currentSession) {
      saveSession(currentSession);
    }
  }, [currentSession]);

  return (
    <div className="h-screen flex flex-col bg-white">
      {/* Header */}
      <header className="h-14 border-b border-gray-200 flex items-center justify-between px-4">
        <h1 className="text-xl font-bold text-gray-800">live-point</h1>
        <RecordButton onStart={handleStart} onStop={handleStop} />
      </header>

      {/* Main */}
      <main className="flex-1 flex overflow-hidden">
        <HistoryPanel />
        <TranscriptFlow />
        <PointPanel />
      </main>
    </div>
  );
}

export default App;
```

**Step 3: index.cssì— ì• ë‹ˆë©”ì´ì…˜ ì¶”ê°€**

```css
@tailwind base;
@tailwind components;
@tailwind utilities;

@keyframes fade-in {
  from { opacity: 0; transform: translateY(-10px); }
  to { opacity: 1; transform: translateY(0); }
}

.animate-fade-in {
  animation: fade-in 0.3s ease-out;
}
```

**Step 4: Commit**

```bash
git add frontend/src/
git commit -m "feat: App ì»´í¬ë„ŒíŠ¸ í†µí•© ë° RecordButton êµ¬í˜„"
```

---

## Task 14: ì „ì²´ ì—°ë™ í…ŒìŠ¤íŠ¸

**Step 1: Backend ì‹¤í–‰**

```bash
cd backend
source venv/bin/activate
cp .env.example .env
# .env íŒŒì¼ì— OPENAI_API_KEY ì„¤ì •
uvicorn main:app --reload --port 8000
```

**Step 2: Frontend ì‹¤í–‰**

```bash
cd frontend
npm run dev
```

**Step 3: ë¸Œë¼ìš°ì €ì—ì„œ í…ŒìŠ¤íŠ¸**

1. http://localhost:5173 ì ‘ì†
2. "ìƒˆ ì„¸ì…˜" í´ë¦­
3. "ë…¹ìŒ" ë²„íŠ¼ í´ë¦­
4. ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©
5. ë§í•˜ê¸° â†’ ê°€ìš´ë° ì „ì‚¬ í™•ì¸
6. ì ì‹œ ë©ˆì¶¤ â†’ ìš°ì¸¡ì— ìš”ì§€ ìƒì„± í™•ì¸

**Step 4: ìµœì¢… Commit**

```bash
git add .
git commit -m "feat: live-point v0.1 ì™„ì„±"
```
